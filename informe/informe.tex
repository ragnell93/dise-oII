\documentclass{ci5652}
\usepackage{graphicx,amssymb,amsmath}
\usepackage[utf8]{inputenc}
\usepackage[USenglish]{babel}
\usepackage{hyperref}
\usepackage{subfigure}
\usepackage{paralist}
\usepackage{csvsimple}
\usepackage{adjustbox}
\usepackage{graphicx}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}

%----------------------- Macros and Definitions --------------------------

% Add all additional macros here, do NOT include any additional files.

% The environments theorem (Theorem), invar (Invariant), lemma (Lemma),
% cor (Corollary), obs (Observation), conj (Conjecture), and prop
% (Proposition) are already defined in the ci5652.cls file.

%----------------------- Title -------------------------------------------

\title{Estudio comparativo entre metaheurísticas de trayectoria y metaheurísticas poblacionales aplicadas al Problema de Asignación Cuadratico}

\author{Antonio Álvarez}

%------------------------------ Text -------------------------------------

\begin{document}
\thispagestyle{empty}
\maketitle

\begin{abstract}
Este trabajo muestra una comparación entre 5 metaheurísticas aplicadas al problema de asignación cuadrática; 3 de trayectoria (Recocido Simulado, Búsqueda Tabú y Búsqueda Local Iterada), 1 poblacional (Algoritmo Genético) y un híbrido (Colonia de Hormigas Híbrida). El objetivo es determinar cual de ellas obtiene mejores resultados para las instancias seleccionadas y para esto se prueban los algoritmos con instancias de la serie chr, sko, tai y esc; una combinación de instancias sintéticas y reales. Al final se obtiene que la Colonia de Hormigas Híbrida genera los mejores resultados para todas las instancias probadas y se concluye que se debe a la integración de una búsqueda local que permite intensificar en regiones del espacio de soluciones y las buenas modificaciones generadas por las hormigas gracias a la matriz de feromonas. 
\end{abstract}

\section{Introducción}

El problema de asignación cuadrática (QAP por sus siglas en inglés) es un problema combinatorio en el cual hay "n" localidades con distancias definidas entre ellas y almacenadas en una matriz D y "n" sucursales con flujos determinados en una matriz F. La idea es asignar cada sucursal a una localidad distinta tal que se minimice la siguiente ecuación: 

\begin {equation*}
\sum_{i=1}^{n} \sum_{j=1}^{n} f_{ij} d_{p(i)p(j)}
\end {equation*}

Para esto hay que hallar una permutación "p"  que lo haga posible \cite{1}. Dicha permutación expresa el orden de asignación de una localidad con respecto a las sucursales o viceversa.

Este problema fue demostrado NP-completo por Sahni, S. y T. Gonzalez \cite{2} lo cual hace que sea infactible una búsqeda exhaustiva en el espacio de soluciones para n de tamaño moderado y grande por ser n! combinaciones posibles. En su lugar se usan algoritmos de aproximación que consigan una respuesta dentro de un margen de error dado y en un tiempo de cómputo razonable.

Estos algoritmos de aproximación empiezan con una solución inicial y dependiendo de los criterios de selección presentes se va moviendo por el espacio de soluciones hasta que se cumple el criterio de parada y devuelve la mejor solución encontrada \cite{4}.

Este problema ha sido base para distintas investigaciones buscando proponer técnicas y optimizaciones con las cuales se pueda hallar los óptimos globales para las distintas instancias. Entre dichas investigaciones se encuentran la realizada por Li, Y. en "Heuristic and exact algorithms for the quadratic assignment problem" \cite{12} donde plantea mejoras a partir de reducciones realizadas a las matrices de flujos y distacias, aporta nuevas cotas con la construcción de un algortimo "branch \& bound" basado en la optimización de las matrices, muestra una nueva versión de búsqueda local con una nueva estructura de vecindad y diseña un algoritmo genético que incluye un nuevo operador de cruce que muestra ser efectivo al combinarse con "local hill-climbing".

Otro trabajo es el de Karisch, S. "Nonlinear approaches for the quadratic assignment and graph partition problems" \cite{11}. Donde logra dar las cotas inferiores más bajas para muchos de los problemas pequeños de la librería a través de la utilización de enfoques no lineales. Por su parte Johnson, T. en "New linear programming-based solution procedures for the quadratic assignment problem" \cite{13}. Plantea procedimientos basados en la programación lineal que van a servir como base a las formulaciones de otros investigadores para resolver QAP.

Este trabajo busca comparar el desempeño tanto en precisión como en tiempo de cómputo de 5 metaheurísticas distintas al buscar él óptimo global para instancias de este problema ; éstas son Recocido Simulado (SA), Búsqueda Tabú (TS), Búsqueda Local Iterada (ILS), Algoritmo genético (GA) y Colonia de Hormigas (AC). El objetivo es determinar cual de estos métodos es el más efectivo al momento de buscar una buena solución al problema de asignación cuadrática.

Al existir un extenso repertorio de metaheurísticas que está en constante expansión, se torna difícil elegir un método a utilizar para la resolución del problema planteado; más aún cuando las carcterísticas de dicho problema afectan el desempeño del método. Por lo tanto existe una constante necesidad de probar las distintas metaheurísticas con cada problema de optimización planteado para determinar su comportamiento ante los mismos. De esta manera, este trabajo espera probar las 5 mencionadas anteriormente y definir, en base a los resultados, cual de ellas se adapta mejor a QAP.

En lo que concierne al resto del informe se tiene la descripción de las 5 metaheurísticas utilizadas y la especificación de sus parámetros en la sección de metodología con el fin de dejar sentadas las bases con las cuales se realizó el experimeto. La sección de resultados presenta las tablas con los promedios de 10 corridas para cada método probado con distintas instancias y un boxplot por cada método para mostrar el desempeño general del mismo. Luego se presenta el análisis de los resultados, donde  se destacan los puntos resaltantes del experimento que conlleven a la determinación del mejor método sobre los demás y finalmente se encuentran las conclusiones donde se generaliza lo ya destacado en el análisis de resultados y se determinan los aportes realizados.

\section{Metodología}

Las soluciones factibles se modelan como un arreglo de enteros de tamaño n con una permutación de los números del 1 al n (incluidos) donde n representa el número de localidades y sucursales. La operación de movimiento o vecindad se define como el intercambio de exactamente 2 elementos dentro del arreglo, por lo tanto la vecindad está formada por $n*(n+1)/2$ elementos distintos. La función objetivo es: $\sum_{i=1}^{n} \sum_{j=1}^{n} f_{ij} d_{p(i)p(j)}$  y una solución es considerada mejor que otra si al evaluarla con la función objetivo se obtiene un resultado menor. 

Para este trabajo se utiliza la librería QAPLIB \cite{5}. Las instancias seleccionadas son las de la serie Chr que representan valores para árboles y grafos completos; la serie Esc que se basan en la prueba de circuitos; Sko con matrices cuyos números son generados aleatoriamente; la serie a de Tai que son generados uniformemente y son simétricas y Wil cuyas distancias son rectangulares.  Cada instancia es probada 10 veces y se reporta el promedio de la evaluación de la función objetivo y tiempo de cada corrida. Las pruebas realizadas fueron hechas con un procesador Intel Celeron N3160, 2GB de RAM usando una versión de 32-bit de Ubuntu 14.04.5. El código de los distintos algoritmos se puede conseguir en: https://github.com/ragnell93/proyecto\_algoritmos\_II

Ahora se procede a la implementación de los distintos algoritmos utilizados:

\subsection{Búsqueda Local}

Búsqueda local se usa como la heurística base con la cual se comparan las otras metaheurísticas. La idea de búsqueda local es ir eligiendo soluciones cada vez mejores en cada iteración hasta que no se consiga ninguna mejoría en la vecindad de la solución actual, situación que da por culminada la búsqueda y da como resultado un óptimo local dentro del espacio de soluciones.

Para la solución inicial se optó por una solución aleatoria porque como explica Talbi, E. G. \cite{6} Con una vecindad de grandes dimensiones se mitiga el impacto que genera la elección de la solución inicial como es el caso de las instancias con más de 100 localidades y para las instancias pequeñas (menos de 30 localidades) el aumento en iteraciones del movimiento por el espacio de soluciones no muestra un impacto importante en el tiempo de cómputo cuando en promedio la evaluación de una instancia de 30 toma 0.12 segundos.

Luego se decidió parametrizar búsqueda local de tal manera que pudiera operar bajo distintos criterios de selección de vecinos en cada iteración; estos criterios son: elegir el primer vecino encontrado que mejore la solución actual, elegir la mejor solución de la vecindad, elegir la mejor solución dentro de un porcentaje dado de la vecindad y elegir un vecino aleatorio.

En los procesos de búsqueda en la vecindad se empieza la permutación ordenada de cada par de elementos dentro del arreglo de la solución de tal manera que se verifiquen todas las combinaciones posibles (excepto para la búsqueda aleatoria). 

En la figura \ref{alg1} se presenta el pseudo-código para la búsqueda local propuesta. Nótese que f es la función objetivo

\begin{algorithm}
 \label{alg1}
 \DontPrintSemicolon
 \vspace*{0.1cm}
 \KwIn{matrices con las distancias y flujos y tipo de selección dentro de la búsqueda}
 \KwOut{Arreglo con una permutación de las asignaciones de las localidades a las sucursales}
 S = S0 \tcc* {escogiendo S0 aleatoriamente}
 \Repeat {f(S) $\neq$  f(S')}{
    Generar vecino S' según el tipo de búsqueda\;
    \If {f(S') $\leq$ f(S)}{
      S = S'\;
    }
 }
 \KwRet{S}
 \vspace*{0.1cm}
 \caption{Busqueda Local}
\end{algorithm}

\subsection{Recocido simulado}
 
 El recocido simulado es una metaheurística propuesta en 1983 por S. Kirkpatrick et al. en su artículo "Optimization by Simulated Annealing" \cite{7}. Se toma como inspiración el proceso metalúrgico por el cual se calienta a altas temperaturas un metal y se enfría lentamente para formar estructuras cristalinas fuertes.
 En su trabajo, Kirkpatrick hace un símil y establece que el proceso de calentamiento y enfriamiento es aplicable a la búsqueda de soluciones para los problemas de optimización.

Esta metaheurística establece que en una búsqueda de soluciones dentro del espacio se realiza una exploración en donde una solución es aceptada si mejora la actual o en caso contrario es aceptada con probabilidad $e^{\frac{-(f(s')-f(s))}{T}}$. Donde f es la función de costos, s' la solución que se está generando y evaluando, s la solución actual y T la temperatura actual.

Por lo tanto, la idea es empezar con una temperatura inicial con la cual se pueda aceptar cualquier movimiento dentro del espacio de soluciones y así promover la diversificación. Luego, pasado cierto tiempo, que puede ser un número de iteraciones en que no hay mejoría o un número fijo, se enfría la temperatura y se repite la búsqueda en la nueva vecindad hasta que se llegue a una temperatura final. Con este esquema, ya cuando se llega a temperaturas bajas la tasa de aceptación debe ser menor que el principio de tal manera que se intensifique la búsqueda en una región específica, la cual debería contener el óptimo global.

Cabe destacar que el proceso de enfriamiento puede llevarse a cabo con distintas funciones, las más comunes son la función geométrica $ T' = \alpha*T$, y logarítmica $Ti = \frac{T0}{log(i)}$. Donde mientras más lenta sea la tasa de decremento, más oportunidad se le da al algoritmo para explorar y poder conseguir el óptimo global.

En este sentido los parámetros que hay que ajustar a las necesidades del problema son: una temperatura inicial que permita aceptar movimientos a cualquier vecino, una temperatura final en la cual ya no se acepten soluciones que empeoren la evaluación de la función de costos, cuántas iteraciones han de evaluarse en cada temperatura y cual es la función con la cual se enfría la temperatura una vez se llegue a un estado de equilibrio.

En la figura \ref{alg2} se muestra el pseudo código del Recocido Simulado para este trabajo. Se estableció como temperatura inicial T0 = 100000, temperatura final Tf = 1000, número de iteraciones para conseguir el equilibrio = 1000 y tasa de enfriamiento = 0.95*T para todas las instancias. La temperatura inicial se elige de tal manera que soluciones con una diferencia de hasta 30000 del anterior puedan ser aceptadas al principio de la búsqueda con un 75\% de probabilidad. La temperatura final elegida rechaza soluciones con una diferencia de más de 3000 con respecto a la anterior con menos del 5\%, intensificando la búsqueda en la región en la que se encuentre el algoritmo al final de la prueba. Por su parte se elige 0.95 como tasa de enfriamiento luego de no notar una mejoría en los resultados al utilizar 0.98.

\begin{algorithm}
 \label{alg2}
 \DontPrintSemicolon
 \vspace*{0.1cm}
 \KwIn{matrices con las distancias y flujos}
 \KwOut{Arreglo con una permutación de las asignaciones de las localidades a las sucursales}
 S = S0 \tcc* {escogiendo S0 aleatoriamente}
 T = 100000 \tcc* {temeratura inicial}
 Tf = 1000 \tcc* {temperatura final}
 \While {T \textgreater Tf}{
    \While {no pasen 1000 iteraciones sin mejorías}{
    Generar vecino S'\;
    $\Delta E = f(S')-f(S)$\; 
    \If {$\Delta E \leq 0$}{S = S'\;}
    \Else {S = S' con probabilidad $e^{\frac{-(f(s')-f(s))}{T}}$\;}
    }
    $T = 0.95*T$\;
 }
 \KwRet{S}
 \vspace*{0.1cm}
 \caption{Recocido Simulado}
\end{algorithm}

\subsection{Búsqueda Tabú}

La búsqueda tabú es una metaheurística propuesta por F. Glover en su trabajo "Tabu search: Part I" \cite{8}. Este método busca escapar de los óptimos locales permitiendo movimientos que empeoren la evaluación de la función de costos siempre que cumplan con un criterio de aspiración o que no esté en la lista tabú (lista de movimientos prohibidos). 

En la versión más sencilla de búsqueda tabú, sólo se implementa la lista tabú; en ella se almacena los rasgos que caracterizan el movimiento que hace el algoritmo en cada iteración de tal manera que al momento de aceptar peores soluciones no se entre en un ciclo por el cual se repitan movimientos. La naturaleza de las estructuras almacenadas en la lista tabú depende directamente del problema a resolver; para problemas combinatorios dicha lista puede almacenar las arista intercambiadas en un problema de grafos o las posiciones intercambiada en un arreglo de elementos.

La búsqueda continúa hasta que se cumple un criterio de parada; entre ellos se encuentran parar la búsqueda luego una cantidad de iteraciones fijas o luego de que pase un número determinado sin mejorar la solución. Para este trabajo se utiliza la segunda.

En la figura \ref{alg3} se muestra el pseudocódigo de la búsqueda tabú utilizada. Para todas las instancias se coloca como condición de parada el paso de 1000 iteraciones sin mejoría de los resultados y una lista tabú de tamaño 10. El tamaño de la lista se eligió al notar una desmejora en los resultados cuando se utilizan listas de tamaño 30 y 50, además que empeoran los tiempos de ejecución.

\begin{algorithm}
 \label{alg3}
 \DontPrintSemicolon
 \vspace*{0.1cm}
 \KwIn{matrices con las distancias y flujos}
 \KwOut{Arreglo con una permutación de las asignaciones de las localidades a las sucursales}
 S = S0 \tcc* {escogiendo S0 aleatoriamente}
 Inicializar la lista tabú \;
 \While {no pasen 1000 iteraciones sin mejorías}{
    Conseguir el mejor vecino S' que no se encuentre en la lista tabú o que sea la mejor solución conseguida hasta el momento \tcc* {criterio de aspiración}
    S = S' \;
    Actualizar la lista tabú con el movimiento realizado
 }
 \KwRet{S}
 \vspace*{0.1cm}
 \caption{Búsqueda Tabú}
\end{algorithm}

\subsection{Búsqueda Local Iterada}

La búsqueda Local Iterada (ILS por sus siglas en inglés) parte de una idea sencilla; conseguir un óptimo local utilizando algún método, perturbar la solución obtenida y repetir el método utilizado para conseguir el óptimo local con el objetivo de conseguir una mejor solución. Este proceso se repite hasta que se cumpla un criterio de parada y se reporta la mejor solución encontrada.

ILS está conformado por 4 componentes que entonar para conseguir la configuración óptima que se adapte al problema en cuestión \cite{9}. Estos son: la solución inicial de la búsqueda, la perturbación realizada sobre el óptimo local encontrado en cada iteración, el criterio de aceptación de los óptimos conseguidos periódicamente y el método utilizado dentro del ciclo para conseguir óptimos locales.

La solución inicial puede ser aleatoria o resultado de un algoritmo ávido; la ventaja de esta última opción involucra una menor cantidad de iteraciones utilizadas por ILS para converger a una solución (salvo en casos específicos en donde la topología juega en contra de obtener mejores resultados a partir de buenas soluciones iniciales) y en algunos problemas puede conllevar a una mejor respuesta final. Sin embargo, si obtener una respuesta por parte de un algoritmo ávido es especialmente costoso se tiende a optar por una solución aleatoria.

Con respecto a la perturbación realizada a la solución obtenida se debe realizar en una medida que le permita escapar del óptimo local en el que se encuentra pero no ser un cambio tan drástico que se pierda todas las características que conforman la respuesta que está perturbando. La idea detrás de esto es conseguir un óptimo local, el cual debe poseer algún rasgo que comparta con el óptimo global y al conservarlo se pueda explorar el espacio de soluciones de manera más efectiva que si se empezara una busqueda aleatoria en cada fase del algoritmo. Un ejemplo de una perturbación moderada para TSP es el cambio de 4 aristas por otras nuevas \cite{9}. El cambio es díficil de deshacer como para regresar a la combinación original y además conserva el resto de la trayectoria original; por lo que si la solución original es buena, la nueva también lo será.

Por su parte, el criterio de aceptación determina cuál solución producida en cada iteración es aceptada como el punto de partida para la siguiente vuelta. Por las características señaladas en \cite{14} varias de las instancias de QAPLIB presentan una topología que lleva a la convergencia prematura a una mala solución, por lo tanto se utiliza un criterio que favorezca la diversificación y cada solución nueva obtenida es aceptada y perturbada para ser utilizada en la siguiente iteración.

Por último se encuentra el método usado en cada iteración para la producción de un óptimo local. Dicho método puede ser un búsqueda local sencilla u otra metaheurística como recocido simulado o búsqueda tabú. En este trabajo se usa la búsqueda local que va eligiendo la primera mejor solución de la vecindad que consiga por su fácil implementación y rapidez de cómputo.

Además se usó como solución inicial una generada aleatoriamente, como perturbación un intercambio de n/3 elementos donde n es el la dimensión del problema, esto con el fin de generar un cambio considerable de acuerdo al tamaño del problema pero manteniendo una buena porción de la solución que va a pasar a la siguiente iteración; la condición de parada es 100 iteraciones sin mejoría; finalmente se incluye un mecanismo de diversificación en el cual si pasan n iteraciones sin mejoría reinicia la búsqueda desde una nueva . En la figura \ref{alg4} el pseudocódigo.

\begin{algorithm}
 \label{alg4}
 \DontPrintSemicolon
 \vspace*{0.1cm}
 \KwIn{matrices con las distancias y flujos}
 \KwOut{Arreglo con una permutación de las asignaciones de las localidades a las sucursales}
 S = S0 \tcc*{elegido aleatoriamente}
 sinMejoria = 0 \;
   \While {sinMejoria \textless 100}{
     S* = localSearch(S)\;
     \If {f(S*) \textless f(S)}{
        sinMejoria = 0 \;
     }
     perturbar S* intercambiando n/3 elementos \;
     S= S* \;
     \If {sinMejoria es múltiplo de n}{
        elegir un S aleatorio y utilizarlo como solución actual\;
     }

     sinMejoria = sinMejoria +1 \;
   }

 \KwRet{S}
 \vspace*{0.1cm}
 \caption{Búsqueda Local Iterada}
\end{algorithm}

\subsection{Algoritmo Genético}

El concepto de algoritmo genético aparece por primera vez en "Adaptation in natural \& artificial systems" gracias a Holland, H. \cite{10}. La metaheurística está inspirada en la teoría evolutiva en la cual la descendencia que presente rasgos genotípicos que le permitan adaptarse al entorno tiende a proliferar más y así pasar dichos rasgos a la siguiente generación. Un algoritmo genético parte de una población de soluciones llamadas cromosomas, aplica un criterio de selección para elegir aquellos que van a reproducirse, cruza las soluciones con algún método, aplica un criterio de reemplazo para determinar cuales cromosomas sobreviven en cada ciclo y uno para las mutaciones que se puedan dar dentro de la población. Luego de que se cumpla un criterio de parada determinado se reporta la mejor solución encontrada.

La selección de la población inicial conlleva a elegir cuántos cromosomas van a conformarla; si son pocos los cromosomas podría no estarse explorando bien el espacio de soluciones con lo cual se restringe la búsqueda a pocos sectores, por otra parte, si son muchos los cromosomas se utiliza más tiempo de cómputo en cada iteración volviendo menos eficiente el algoritmo; por lo tanto una cantidad moderada es deseable y dicha cifra está sujeta a cada instancia con la que se prueba el algoritmo. 

La selección por su parte puede ser completamente elitista con un sistema de jerarquización en el cual se ordenan los cromosomas de peor a mejor resultado y la probabilidad de elegir un cromosoma en específico es $\alpha+\beta*k$ donde k es el índice del cromosoma en la lista ordenada; así se da mayor peso a los mejores resultados al momento de hacer la elección. Otro sistema utilizado es el torneo, en el cual se toma un número aleatorio de cromosomas y se elige el mejor de la muestra.

En lo concerniente al cruce se tiene que el método a emplear es dependiente del problema a resolver. Para arreglos de permutaciones como en QAP se encuentra OX, éste consiste en utilizar una máscara de bits con el cual se fijan en los hijos los elementos de los padres que coincidan en posición con los 1s y se va rellenando los elementos faltantes en el orden de aparición que tengan en el otro padre.

El reemplazo puede ser generacional, en donde la progenie reemplaza a los padres excepto al mejor y así evitar que se pierda la posible solución final o puede ser bajo un criterio donde los hijos reemplazan a los padres si son mejores que éstos o a las peores soluciones de la población. Nótese que esta última opción es elitista y puede llegar a homogeneizar la población, convergiendo prematuramente a un óptimo local no deseado.

En lo referente a la mutación se debe determinar la frecuencia con la que ocurre, qué cromosomas mutan y cuáles son los genes que cambian. El cambio de los genes en el cromosoma que muta debe ser tal que produzca una solución "cercana" a la original, si el problema puede ordenar los valores de los genes es recomendable elegir valores próximos para asegurar dicha cercanía.

Finalmente la condición de parada puede ser un número estático de iteraciones, una cantidad de ciclos sin mejoría de la mejor solución o forzar la culminación cuando la diversidad de la población baje de cierto punto. Para este trabajo se utiliza una población inicial de 10 cromosomas para mantener los tiempos de cómputo competitivos con las metaheurísticas de trayectoria, además que en pruebas empíricas no se obtuvo mejores resultados con poblaciones de 30 y 50; como condición de parada 3000 iteraciones sin mejoría de la solución óptima encontrada; se usa el torneo de 3 cromosomas para la seleción de los individuos a reproducirse; el operador de cruce es OX eligiendo dos genes aleatoriamente; la mutación puede ocurrir en cada iteración con un 10\% de probabilidad sobre un número aleatorio de cromosomas de la población, se eligen 2 genes aleatoriamente para su intercambio y los hijos reemplazan a los padres si son mejores que ellos. En la figura  \ref{alg5} se muestra el pseudocódigo.

\begin{algorithm}
 \label{alg5}
 \DontPrintSemicolon
 \vspace*{0.1cm}
 \KwIn{matrices con las distancias y flujos}
 \KwOut{Arreglo con una permutación de las asignaciones de las localidades a las sucursales}
 Se inicializa la población con 10 soluciones aleatorias \;
 Se ordenan los cromosomas de mejor a peor solución \;
 sinMejoria = 0 \;
 \While {sinMejoria \textless 3000}{
   Elegir 2 padres realizando un torneo de 3 cromosomas aleatorios por cada uno\;
   Cruzar los padres con el operador OX \;
   Elegir los 2 mejores entre los hijos y los padres y colocarlos en la población en la posición de los padres \;
   \If {número aleatorio entre 0 y 1 \textless 0.10}{
     Elegir aleatoriamente los cromosomas que van a mutar e intercambiar dos genes aleatoriamente \;
   }
   Reordenar la población con quicksort\;
   sinMejoria = sinMejoria + 1\;
 }
 \KwRet{Mejor resultado}
 \vspace*{0.1cm}
 \caption{Algoritmo genético}
\end{algorithm}

\subsection{Colonia de Hormigas Híbrida}

La colonia de hormigas se basa en el comportamiento natural de las hormigas de encontrar el camino más corto a una fuente de alimentos dejando un rastro volátil de feromonas. Esta metaheurística toma esta idea para la obtención de una buena solución al problema dado. Cada hormiga representa una herramienta que va construyendo soluciones factibles con la información dada por las feromonas; dichas feromonas representan un rastro sobre los elementos que conforman una solución que le indica a cada hormiga cuán frecuente es utilizado dicho elemento en soluciones o cuán deseado es que esté presente ese elemento en las siguentes soluciones y por estos motivos las feromonas se representan numéricamente y en estructuras de almacenamiento como vectores o matrices.

El algoritmo parte con un número de hormigas sin soluciones construidas y una estructura de feromonas inicializada equitativamente entre todos sus elementos, luego las hormigas empiezan a construir soluciones con información de las feromonas y refuerzan el rastro de los componentes que fueron utilizados; este refuerzo puede ser hecho al momento en que la hormiga lo utiliza o una vez armadas todas las soluciones de la iteración actual; acto seguido se evaporan en base a un coeficiente todas las feromonas de tal manera que se baje la probabilidad de usar una componente poco visitada por las hormigas y se filtren las mejores que puede dar a lugar la obtención del óptimo global.

En pruebas preliminares esta concepción sencilla de colonia de hormigas no dió buenos resultados para QAP, por lo que este trabajo se basa en el método propuesto por Taillard, É en \cite{15} donde se combina colonia de hormigas con búsqueda local (HAC por sus siglas en inglés). Taillard plantea inicializar las hormigas con soluciones factibles aleatorias y aplicarles una búsqueda local para obtener óptimos locales; se inicializa la matriz de feromonas con entradas de $\frac{1}{Q*f(\phi*)}$ donde $\phi*$ es el mejor de los óptimos locales; una entrada ij de la matriz de feromonas indica cuán deseable es que la sucursal j esté en la localidad i. 

Luego procede a a realizar R intercamibos entre 2 elementos del vector solución de cada hormiga eligiendo aleatoriamente el primer índice r y el segundo s con probabilidad $\frac{\tau_{r\phi_s} + \tau_{s\phi_r}}{\sum_{j \neq r} (\tau_{r\phi_j} + \tau_{j\phi_r})}$ ($\tau_{ij}$ representa la entrada ij de la matriz de feromonas) de tal manera que tengan más oportunidades las combinaciones que han pertenecido a buenas soluciones para obtener $\phi~$. Acto seguido se aplica búsqueda local a los $\phi$' para obtener $\phi$''; si la intensificación está activada entonces se decide cuál es el mejor entre $\phi$ y $\phi$'' donde $\phi$ era la solución original y se le asigna a la hormiga correspondiente, si la intensificación está desactivada $\phi$'' pasa a ser la solución que la hormiga va a utilizar en la siguiente iteración. Si en un ciclo todas las hormigas quedan con soluciones viejas en vez de actualizarse se apaga la intensificación y si se consigue obtener una mejor solución hasta el momento se activa, la idea es darle un tiempo al algoritmo de actualizar la matriz de feromonas cada vez que consiga una mejor solución para que refleje cuáles componentes la conforman.

Decidido las soluciones que se van a usar en la siguiente iteración se procede a evaporar los elementos de la matriz a una tasa de $\alpha_1 * \tau_{ij}$ para todo i,j y se actualiza los elementos que conforman la mejor solución de la iteración con $ \tau_{i\phi_i} = \tau_{i\phi_i} + \frac{\alpha_2}{f(\phi*)}$.

Finalmente, si pasan S iteraciones sin actualizar la mejor solución encontrada se reinicializan las hormigas (dejando la mejor respuesta del grupo en una hormiga) además de la matriz de feromonas pero ahora tomando en cuenta la mejor solución encontrada hasta el momento.

Los parámetros se fijaron en 10 hormigas porque en las pruebas de Taillard muestra que menos de 8 no es suficiente para que escapar de una convergencia prematura de las soluciones y más de 15 no mejora los resultados demorando además la ejecución del algoritmo; Q = 100 para la inicialización de la matriz de feromonas, R = n/3 donde n es el tamaño del problema para el número de intercambios, $\alpha_1 = 0.9$ en la tasa de evaporación y $\alpha_2 = 0.1$ en la tasa de reforzamiento y S = n/2 en el número de iteraciones sin mejorías; el número de vueltas antes de detener el algoritmo fue 10 para las instancias menores de 70 localidades y 5 para las mayores de 70. En la figura \ref{alg6} se muestra el pseudocódigo propuesto por Taillard. 

\begin{algorithm}
 \label{alg6}
 \DontPrintSemicolon
 \vspace*{0.1cm}
 \KwIn{matrices con las distancias y flujos}
 \KwOut{Arreglo con una permutación de las asignaciones de las localidades a las sucursales}
 Se inicializan las 10 hormigas con soluciones aleatorias $\phi^1$,...,$\phi^k$ \;
 Se mejoran estas soluciones con búsqueda local \;
 Sea $\phi*$ la mejor solución \;
 Inicializar la matriz de feromonas T \;
 Activar la intensificación \;
 \For{i=1 hasta $I^{max}$}{
   \tcc*{manipulación de soluciones}
   \For{cada $\phi^k(i)$ ($1 \leq k \leq 10)$}{
     Aplicar n/3 intercambios basados en las feromonas a $\phi^k$(i) para obtener $\phi$' \;
     Aplicar búsqueda local a $\phi$' para obtener $\phi$''\;
     \tcc*{Intensificación}
     \For { cada hormiga k}{
        \If {Intensificación está activa}{
            $\phi^k$(i+1) \textless- mejor permutación entre $\phi^k$(i) y $\phi^k$''(i)
        }
        \Else {$\phi^k$(i+1) \textless- $\phi^k$''(i)}
     }
    }
     \If{$\phi^k$(i+1) = $\phi^k$(i) $\forall$ k}{desactivar la intensificación}
     \If{$\exists$ k tal que f($\phi^k$''(i)) \textless f($\phi*$)}{
        Actualizar $\phi*$, la mejor solución encontrada hasta el momento \;
        Activar la intensificación \; 
     }
     \tcc*{Actualización de la matriz de feromonas}
     Evaporar las feromonas $ \tau_{ij} = \alpha_1 * \tau_{ij} \forall i,j$ \;
     Reforzar los componentes de la mejor solución $\tau_{i\phi_i} = \tau_{i\phi_i} + \frac{\alpha_2}{f(\phi*)}$ \;
     \tcc*{diversificación}
     \If{Si pasan S iteraciones sin mejorar $\phi*$ }{Reinicializar las hormigas conservando la mejor solución y la matriz de feromonas}
 }
 \KwRet{Mejor resultado}
 \vspace*{0.1cm}
 \caption{Colonia de Hormigas Híbrido}
\end{algorithm}

\section{Resultados y análisis}

\begin{table}
\csvautotabular[before reading=\caption{Resultados de la evaluación de la función objetivo de las distintas búsquedas locales}\label{tabla1}\begin{adjustbox}{max width=\columnwidth},
after reading=\end{adjustbox}]{resultadosLocal.csv}
\end{table}

\begin{table}
\csvautotabular[before reading=\caption{Resultados de la evaluación de la función objetivo de las distintas metaheurísticas}\label{tabla2}\begin{adjustbox}{max width=\columnwidth},
after reading=\end{adjustbox}]{resultados.csv}
\end{table}

\begin{table}
\csvautotabular[before reading=\caption{Resultados de la evaluación de la función objetivo de las distintas metaheurísticas para las instancias Tai}\label{tabla3}\begin{adjustbox}{max width=\columnwidth},
after reading=\end{adjustbox}]{resultadosTai.csv}
\end{table}

\begin{table}
\csvautotabular[before reading=\caption{Resultados de la evaluación de la función objetivo de las distintas metaheurísticas para las instancias Esc}\label{tabla4}\begin{adjustbox}{max width=\columnwidth},
after reading=\end{adjustbox}]{resultadosEsc.csv}
\end{table}

\begin{table*}[p]
\csvautotabular[before reading=\caption{Porcentajes del error relativo y tiempo de cómputo en segundos de las distintas búsquedas locales}\label{tabla5}]{error&tiempoLocal.csv}
\end{table*}  

\begin{table*}[p]
\csvautotabular[before reading=\caption{Porcentajes del error relativo y tiempo de cómputo en segundos de las distintas metaheurísticas}\label{tabla6}]{errores&tiempos.csv}
\end{table*}             


\begin{table*}[p]
\csvautotabular[before reading=\caption{Porcentajes del error relativo y tiempo de cómputo en segundos de las distintas metaheurísticas para las instancias Tai}\label{tabla7}]{erroresTai.csv}
\end{table*} 

\begin{table*}[p]
\csvautotabular[before reading=\caption{Porcentajes del error relativo y tiempo de cómputo en segundos de las distintas metaheurísticas para las instancias Esc}\label{tabla8}]{erroresEsc.csv}
\end{table*} 

\begin{figure*}[p]
\caption{Boxplot con los errores relativos de las distintas metaheurísticas}
\includegraphics[width=\linewidth]{erroresTotales.png}    
\label{fig1}
\end{figure*}

\begin{figure*}[p]
\caption{Boxplot con los tiempos de Cómputo de las distintas metaheurísticas}
\includegraphics[width=\linewidth]{tiemposTotales.png}    
\label{fig2}
\end{figure*}

Las tablas \ref{tabla1} y \ref{tabla5} muestran los resultados de la evaluación de la función objetivo, los porcentajes de error y tiempo de cómputo para las distintas variantes de búsqueda local (elección de la mejor solución dentro de la vecindad, primera solución que mejore la evaluación de la función de costo actual o elección aleatoria de un vecino) respectivamente.

El error relativo muestra que las instancias sko muestran una topología con pocas mesetas (puntos en los cuales se encuentran los óptimos locales), por lo que se puede aproximar a una buena solución (aquellas que están a no más de 5\% de error) con una búsqueda local que se enfoque en el mejor de la vecindad o el primer vecino que mejore. Sólo las instancias chr presentan errores mayores al 20\%.

Con respecto al desempeño de los distintos tipos de búsqueda local, se muestra una notoria diferencia entre una búsqueda moviéndose por el mejor de la vecindad y por el primero que mejore la solución con respecto a una búsqueda aleatoria. Esta última presenta errores superiores al 15\% en la mayoria de sus instancias y con desempeños mediocres en las instancias chr y esc128, los cuales superan el 100\%.

Comparando una búsqueda local que se mueve al mejor de la vecindad con una que se mueve al primero que mejore la solución, se muestra un mejor desempeño por parte de la segunda sobre la primera; en general se aprecia una diferencia de aproximadamente 2\% de error entre una y la otra, casos como chr15a muestran una acentuada diferencia con 10\% de error a favor de moverse al primer vecino que mejore la solución. Sin embargo hay casos como chr22a y esc128 que se inclinan a favor de una búsqueda basada en el mejor de la vecindad.

Al momento de comparar tiempos de cómputo, la búsqueda aleatoria muestra el mejor desempeño entre los 3 con tiempos que nunca llegan al segundo inclusive para la instancia más grande de 128 localidades. Por su parte, los dos otros métodos muestran un desempeño similar en tiempo para instancias pequeñas y medianas y se evidencia una diferencia es a partir de instancias grandes como sko81, donde se torna a favor de la búsqueda local moviéndose por el primer mejor vecino. Por lo tanto, se evidencia que a partir de instancias de 81 localidades la búsqueda considerando el primer mejor vecino empieza a mostrar ventaja.

La marcada diferencia en tiempos de ejecución entre la búsqueda aleatoria y el resto se debe a que es menos costoso ir generando un par de números aleatorios en cada iteración a tener que recorrer el arreglo de la solución cambiando cada par posible de posiciones. Por su parte, la diferencia entre la búsqueda del mejor de la vecindad y el primer mejor viene dado porque en la primera se debe examinar toda la vecindad, mientras que en la segunda se examina parcialmente; esta diferencia es menos notoria cuando las instancias son pequeñas y medianas (menor a 70 localidades) ya que una vecindad, como se reseñó anteriormente tiene $n*(n+1)/2$ candidatos.

Tomando en consideración los errores relativos y los tiempos de cómputo se nota un mejor desempeño por la búsqueda local con el primer mejor sobre el resto al considerar que en las intancias grandes tarda menos en computar que una busqueda local considerando el mejor de la vecindad y que el error relativo es parecido y hasta mejor.

Ahora pasando a los resultados de la evaluación de las distintas metaheurísticas se presentan los resultados de la evaluación de la función de costos, el porcentaje de error relativo y los tiempos de ejecución en las tablas \ref{tabla2}, \ref{tabla3}, \ref{tabla4}, \ref{tabla6}, \ref{tabla7}, \ref{tabla8}.

Empezando con las metaheurísticas de trayectoria en general TS tuvo el mejor desempeño de las 3. Al revisar la tabla \ref{tabla6} se observa como en promedio TS tiene 7.7\% de error, mientras que ILS posee 19.88\% y SA 55.39 \%. Al desglosar estos resultados evaluando las instancias individuales se observa que TS tuvo errores relativos consistentes por debajo del 10\% en la mayoría de las instancias a excepción de chr25a y esc128, los cuales presentan 29.48\% y 15.63\% respectivamente. Más aún, si se baja la cota a 5\% como margen de soluciones aceptables TS tiene 5 soluciones de 12 en esta categoría.

Por su parte ILS presenta en promedio 19.88\% de error; al igual que TS tiene 5 soluciones con errores por debajo del 5\%, pero de resto presenta errores superiores al 10\%, siendo las instancias chr las que presentan un peor desempeño con chr25a como la peor con 61.67\% cuando TS devuelve resultados para esta instancia con 29.48\% de error en promedio. Finalmente SA presenta en promedio 55.39\% de error que es atribuible a los resultados de las instancias chr20a, chr25a y esc128; los cuales muestran errores de 98.39\%, 180.8\% y 245.31\%. Además el resto de las instancias muestran resultados superiores al 10\% con sólo la instancia chr12a por debajo del 5\%, posicionando así a SA como el peor de las 3 metaheurísticas para evaluar las instancias chr y sko en general. 

Cabe destacar que los tiempos de cómputo a partir de la instancia sko42 se restringen a los tiempos obtenidos por SA de tal manera que se pueda comparar resultados obtenidos por los 3 métodos en tiempos similares. 

Pasando a los resultados de la instancias de la serie Tai se encuentra un comportamiento similar por parte de TS donde sigue siendo el que presenta mejores resultados de los 3 con 1.59\% de error promedio, con una cota superior de 2.51\% obtenida de tai60a. Por su parte SA presenta un error promedio de 2.36\%, mostrando un buen desempeño en todas las instancias y siendo el peor resultado 3.3\% en tai60a. ILS en esta oportunidad figura de último con un error promedio de 5.28\%, presentando una diferencia notoria en general con respecto a los otros 2 métodos al observar que aparecen resultados por encima de 5\% de error y con un máximo de 8.55\% en chr12a.

En esta oportunidad se vuelve a restringir los tiempos de cómputo de Tabu Search e ILS a partir de la instancia tai25a para comparar el desempeño de los algoritmos fijado a un tiempo; este tiempo es el que demora SA en culminar con las especificaciones dadas.

Finalmente, al revisar los resultados de la serie Esc Tabu Search es de nuevo el mejor de los 3 con 3.15\% de error promedio, destacando que se obtuvo el óptimo en 7 instancias de 11 y la presencia de 2 instancias que superan el 10\%, éstas son esc32a y esc23b con 13.08\% y 17.86\%. Si se observa los resultados de ILS se tiene un 7.9\% de error promedio que es producto de los elevados errores obtenidos en esc16d, esc16e, esc32a y esc32b que se encuentran sobre 10\% y con esc32b presentando 31.54\%. De último se encuentra SA con 34.99\% de error promedio con especial énfasis en esc32a, esc32b y esc64a que presentan 117.69\%, 104.76\% y 74.14\% respectivamente; contrastanto fuertemente con los resultdados de instancias como esc16b y esc32e donde se consigue el óptimo global o esc16c que está por debajo del 5\%.

En esta oportunidad se fijó el tiempo de cómputo para los algoritmos al obtenido por TS debido a que consiguió los óptimos globales y buenas solucioes para la mayoria de las instancias en menor tiempo que las otras dos metaheurísticas. Todas los esc16 y esc32 se limitaron a corridas de 2 segundos y esc64 a 10 segundos.

Evaluando la metaheurística poblacional, el Algoritmo Genético, se obtienen peores resultados que las metaheurísticas de trayectoria TS e ILS, en la tabla \ref{tabla6} GA obtuvo 29.42\% de error en promedio con todos los resultados por encima de 5\%, siendo chr25a el peor resultado con 86.49\%. Al revisar los resultados de la serie Tai en \ref{tabla7} GA queda como la peor metaheurística con 8.35\% de promedio, sin tener errores por debajo de 5\% y para la serie Esc en \ref{tabla8} se obtiene 10.45\% de error promedio siendo notorio los errores de esc32a y esc32b con 43.85\% y 48.81\% respectivamente. Cabe destacar que los tiempos de cómputo se limitaron a los de ILS y TS.

Por su parte el híbrido de colonia de hormigas presenta los mejores resultados. En \ref{tabla6} se obtiene el más bajo de los promedios con 4.28\%; dando mejores soluciones a las instancias chr que el resto de las metaheurísticas. En la serie Tai \ref{tabla7} queda de segundo con un promedio de 1.91\% y en la serie Esc \ref{tabla8} queda de primero con un error promedio de 0.28; dando los óptimos globales para todas las instancias excepto esc32a para la cual obtiene 3.08\%. Sin embargo los tiempos requeridos por HAC son mucho mayores que el resto de las metahuerísticas producto de realizar búsquedas locales constantemente para la solución de cada hormiga, lo que hace que fuese imposible restringir la búsqueda a los tiempos de las otras metaheurísticas sin afectar fuertemente el desempeño del método; sólo en la serie Esc se pudo restringir a los tiempos presentados sin perder precisión.

Al revisar los boxplots en la figura \ref{fig1} se observa como SA es el más inestable de todos los métodos al poseer la mayor cantidad de "outliers", que además presentan la mayor distancia de separación con respecto a la mediana (el "outlier" más lejano está cerca de 250\% mientras que la mediana se encuentra alrededor del 10\%); ésta por su parte es de las más elevadas junto a la de GA. Estos resultados de SA se deben a los eleveados errores de las instancias chr y esc, lo cual muestra una imposibilidad para obtener respuestas satisfactorias de los problemas reales, mientras que para los problemas sintéticos de Tai se obtienen resultados razonables con un promedio de 2.41\%.

Búsqueda Tabú por su parte se muestra como uno de los mejores métodos con una mediana de 2\% y 4 "outiers", siendo el mayor de alrededor de 30\%; muestra un buen desempeño tanto para los problemas reales como para los sintéticos y si se toma en cuenta el tiempo logra dichos resultados en menor tiempo que HAC. Los "outliers" representan problemas para los cuales las otras metaheurística a excepción de HAC tienen problemas con errores elevados como chr15a, chr20a, esc32a y esc32b.

Búsqueda Local Iterada muestra una mediana de 5\%; mayor que la de TS y HAC pero mejor que GA y SA. Junto a los 4 "outliers" que comparte con Tabu Search, ILS muestra mayor estabilidad que SA pero peores resultados en general que TS y HAC. El Algoritmo genético por su parte muestra un desempeño mediocre con una mediana de más de 5\% y muchos outliers, lo cual es síntoma de una convergencia prematura para varias instancias.

Por último se encuentra la Colonia de Hormigas Híbrida, la cual presenta los mejores resultados con una mediana de 1\% y sólo 2 "outliers", con el mayor siendo de 19\%. HAC meustra ser capaz de obtener buenos resultados para los problemas sintéticos y reales y compite con TS como mejor metaheurística solo teniendo en contra los tiempos de cómputo.
 
Los resultados de Recocido Simulado se pueden explicar porque no se le dió suficiente tiempo para mejorar las soluciones encontradas. Como se demuestra en \cite{7} si se deja computando SA en un tiempo que tienda al infinito la solución converge al óptimo global. Otro factor que puede estar afcetando es la solución inicial que siendo aleatoria puede influir en el tiempo necesario para converger a una buena solución. Por los resultados obtenidos, SA necesita modificaciones en su implementación que agreguen información de la instancia a trabajar para poder conseguir buenas soluciones en poco tiempo.

La búsqueda tabú logra beneficiarse de una lista reducida de movimientos prohibidos que le permite explorar partes del espacio de soluciones no visitadas que conllevan a los resultados obtenidos. Por su parte Búsqueda Local Iterada presenta peores resultados que las otras dos metaheurísticas de trayectoria al no conseguir una operación de perturbación que posicionara la búsqueda en mejores regiones en cada iteración; ni siquiera la medida de diversificación en la que se parte de una solución aleatoria cada cierto número de iteraciones pudo mejorar considerablemente las soluciones. Para este caso se recomienda explorar la posibilidad de utilizar propiedades de las instancias como  lo propuesto en \cite{14}, donde usa el concepto de dominancia de flujo con la cual se provee al algoritmo de información de donde se concentran los mayores costos de flujo entre localidades y guía las perturbaciones en direcciones por las cuales se pueda minimizar dichos costos.

Las fallas del algoritmo genético se encuentran en la convergencia prematura de sus cromosomas. Cambios en la tasa de mutación de tal manera que ocurra con mucha mayor frecuencia (se probó con 40\%) y modificando la mutación para que sea más drástica (se probó con un intercambio de n/3 elementos, donde n es el tamaño del problema) devuelve mejores resultados ocacionalmente pero al momento de promediar no se logra mejoría al obtener además malos resultados, volviendo inestable el algoritmo. En este caso se recomienda lo propuesto por Fleurent, C. en \cite{16}, donde mezcla las operaciones de los algoritmos genéticos con una búsqueda tabú y obtiene buenos resultados para las instancias probadas en su trabajo. Si se observa la Colonia de Hormigas Híbrida se reafirma lo encontrado por Fleurent al obtener muy buenos resultados al combinar una búsqueda local con la diversificación sistemática obtenida de trabajar varias soluciones a la vez con las hormigas y usando el rastro de feromonas. 


\section*{Conclusiones}

En este trabajo se presentó una comparación de desempeño de 5 metaheurísticas con instancias de las series chr, sko, tai, wil y esc de la librería QAPLIB. Por los resultados obtenidos, tanto las metaheurísticas de trayectoria como las poblacionales presentan fallas que resultan en soluciones mediocres si se implementan en versiones sencillas sin información adicional y sin alteraciones tomando ideas de otros métodos. Las metaheurísticas de trayectoria tienden a quedarse atrapados en óptimos locales con dificultad de salir y explorar otras regiones y las metaheurísticas poblacionales tienden a tener problemas intensificando en una región de interés.

Queda en evidencia, además, la influencia que ejerce la naturaleza de la instancia sobre el desempeño de las metaheurísticas; en general los distintos métodos obtuvieron mejores resultados para las instancias sintéticas como la serie Tai en comparación con las instancias reales de la serie Chr. Esto hace relucir la necesidad de incorporar información pertinente al problema a los distintos métodos que guíen la búsqueda por espacios no explorados y de especial interés que ayuden a escapar de óptimos locales y de convergencias prematuras. Propuestas como la hecha por Stützle de incorporar las áreas de densidad de las matrices de flujo y distancia a ILS presentan una mejoría para las instancias con matrices irregularmente distribuidas.

Por otra parte la combinación de metaheurísticas es una propuesta atractiva si se observa los trabajos como los de Fluerent \& Ferland con su algoritmo genético con búsqueda tabú, la cual identifica el problema de temprana convergencia de un algoritmo genético puro para mucha de las instancias de la librería QAPLIB y propone utilizar una búsqueda tabú con la cual se pueda intensificar en las regiones que evidencian buenas soluciones mientras que se mantiene la diversidad al mantener una población con activa mutación y cruce.

Es así como los resultados obtenidos evidencian una inclinación a obtener los mejores resultados si se combinan principios de las metaheurísticas de trayectoria con principios de las metaheurísticas poblacionales como lo es el caso de la Colonia de Hormigas Híbrida realizada por Taillard, la cual obtuvo los mejores resultados en general tanto para las instancias sintéticas como las reales que se probaron. Dando los óptimos globales a casi todas las instancias de la seria Esc y teniendo los mejores resultados para la serie Chr. Sin embargo los tiempos de cómputo pueden crecer notoriamente como se observa al comparar los tiempos de cómputo entre la Colonia de Hormigas y la búsqueda tabú. Lo que convierte a la búsqueda tabú como el segundo candidato a usar para resolver las instancias probadas en este trabajo si se necesita una respuesta no tan precisa en menor tiempo que el requerido por HAC. 

Con lo anteriormente expuesto se concluye que la implementación utilizada de Recocido Simulado y Algoritmo Genético son los peores métodos a usar para las instancias trabajadas debido a la sencillez de su planteamiento, su falta de incorporación de información referente al problema y poca flexibilidad en intensificación y diversificación respectivamente. Mientras que la Colonia de Hormigas Híbrida es la mejor opción de las estudiadas gracias a la incorporación de una búsqueda local que intensifica en base a las soluciones construidas por las hormigas y se mueve por el espacio eficientemente gracias a la matriz de feromonas. 

La recomendación principal que se deriva de este trabajo es probar las distintas combinaciones que se pueden obtener entre metaheurísticas de trayectoria y poblacionales; siempre moldeando las implementaciones al problema dado con información que pueda hacer más efectiva la búsqueda.

%---------------------------- Bibliography -------------------------------

% Please add the contents of the .bbl file that you generate,  or add bibitem entries manually if you like.
% The entries should be in alphabetical order
\small
\bibliographystyle{abbrv}

\begin{thebibliography}{99}

\bibitem{1}
Burkard, R. et al.
\newblock QAPLIB-A Quadratic Assignment Problem Library.
\newblock 2002

\bibitem{2}
Sahni, S., and Gonzalez, T.
\newblock P-complete approximation problems.
\newblock {\em J. of ACM}, 23, 555–565. 1976

\bibitem{3}
Misevičius, A.
\newblock A modified simulated annealing algorithm for the quadratic assignment problem
\newblock {\em Informatica}, 14(4), 497-514. 2003

\bibitem{5}
Burkard, R. et al.
\newblock Quadratic Assignment Problem.
\newblock http://anjos.mgi.polymtl.ca/qaplib/ . 2002

\bibitem{4}
Talbi, E. G. 
\newblock Metaheuristics: from design to implementation
\newblock {\em John Wiley} 2009

\bibitem{6}
Ibid. 101

\bibitem{7}
S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi. 
\newblock Optimization by simulated annealing.
\newblock {\em Science}, 220(4598):671–680, 1983.

\bibitem{8}
Glover, F. 
\newblock Tabu search: Part I. 
\newblock {\em ORSA Journal on Computing}, 1(3):190–206, 1989.

\bibitem{9}
Lourenço, H.
\newblock Iterated Local Search
\newblock {\em Kluwer's International Series}, 340-352, 2003.

\bibitem{10}
Holland, J.
\newblock Adaptation in Natural and Artificial Systems 
\newblock {\em University of Michigan Press}, Ann Arbor, Michigan, 1975.

\bibitem{11}
Karisch, S. 
\newblock Nonlinear approaches for the quadratic assignment and graph partition problems.
\newblock {\em Graz University of Technology}, Graz, Austria, 1995.

\bibitem{12}
Li, Y.
\newblock Heuristic and exact algorithms for the quadratic assignment problem.
\newblock {\em The Pennsylvania State University}, EEUU, 1992.

\bibitem{13}
Johnson, T.
\newblock New linear programming-based solution procedures for the quadratic assignment problem
\newblock {\em Clemson University}, Clemson, EEUU, 1992.

\bibitem{14}
Stützle, T.
\newblock Iterated Local Search for the Quadratic Assignment Problem
\newblock Darmstadt, Alemania

\bibitem{15}
Taillard, É., Gambardella, L.
\newblock Ant Colonies for QAP
\newblock {\em technical report, Idsia}, Lugano, Suiza.

\bibitem{16}
Fleurent,C., Ferland, J.
\newblock Genetic Hybrids for the Quadratic Assignment Problem
\newblock {\em DIMACS}, 1992.

\end{thebibliography}

\end{document}